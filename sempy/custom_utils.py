from sempy.fabric import get_workspace_id,get_lakehouse_id,list_workspaces,list_datasets, list_partitions
from sempy_labs import refresh_semantic_model
import pandas as pd
import ipywidgets as widgets
from IPython.display import display, HTML
import warnings
warnings.filterwarnings("ignore")

#This function works with Python Runtime.
#Extracts semantic models and its tables/partitions from all the premium workspaces that the user has access too..
#For the first run set the load_from_lakehouse parameter to 'false', 
def get_model_details(load_from_lakehouse: bool,table_name: str,workspace_list: list = None,only_premium_ws: bool=True) -> pd.DataFrame:
    """ Function to extract all semantic models and its tables and partitions of the executing user.

        load_from_lakehouse: set to False will extract the latest information across all the semantic models and writes to lakehouse.
        table_name: name of the lakehouse table. 
        workspace_list: ['Workspace1','Workspace2'], if not provided it will extract all the accesible workspaces data
        only_premium_ws: by default set to True to fetch only premium workspaces
    """
    from deltalake import DeltaTable, write_deltalake
    workspace_id, lakehouse_id = get_workspace_id(), get_lakehouse_id()
    table_path = f"abfss://{workspace_id}@onelake.dfs.fabric.microsoft.com/{lakehouse_id}/Tables/{table_name}"
    if load_from_lakehouse: #Reads the existing data from the lakehouse
        try:
            delta = DeltaTable(table_path)
            result_df = delta.to_pyarrow_dataset().to_table().to_pandas()
            if workspace_list and only_premium_ws:
                result_df = result_df[(result_df["Workspace Name"].isin(workspace_list)) & (result_df['Workspace Flag']==True)]
            elif workspace_list and not only_premium_ws:
                result_df = result_df[result_df["Workspace Name"].isin(workspace_list)]
            print(f"‚úÖ Found {len(result_df['Dataset Id'].unique())} models info from {len(result_df['Workspace Id'].unique())} workspaces")
        except:
            result_df = pd.DataFrame()
            print('üî¥ Please attach a lakehouse or Table with mentioned name not found, if running for the first time set load_from_lakehouse to False')
    else:
        premium_filter = 'isOnDedicatedCapacity eq true' if only_premium_ws else None
        _workspaces = list_workspaces(filter=premium_filter)
        if workspace_list:
            _workspaces = _workspaces[_workspaces["Name"].isin(workspace_list)]
        all_datasets = []
        dataset_partitions = []
        for idx1,row1 in _workspaces.iterrows():
            datasets = list_datasets(workspace=row1['Id'],mode='rest')[['Dataset Id','Dataset Name']]
            for idx2,row2 in datasets.iterrows():
                try:
                    partitions = list_partitions(workspace=row1['Id'],dataset=row2['Dataset Id'])[['Table Name','Partition Name']]
                    partitions = partitions[~partitions['Table Name'].str.startswith('LocalDateTable') & 
                                            ~partitions['Table Name'].str.startswith('DateTableTemplate')]
                                            #Add your own filters here if I had missed other scenarios..
                    partitions['Dataset Id'] = row2['Dataset Id']
                    dataset_partitions.append(partitions)
                except:
                    continue
            datasets['Workspace Id'] = row1['Id']
            datasets['Workspace Name'] = row1['Name']
            datasets['Workspace Flag'] = row1['Is On Dedicated Capacity']
            all_datasets.append(datasets)
        datasets_df = pd.concat(all_datasets,ignore_index=True)
        partitions_df = pd.concat(dataset_partitions,ignore_index=True)
        result_df = datasets_df.merge(partitions_df,on='Dataset Id', how='inner')
        write_deltalake(table_path, result_df, mode='overwrite') #write the dataframe to a lakehouse table
        print(f"‚úÖ Extracted {len(result_df['Dataset Id'].unique())} models info across {len(result_df['Workspace Id'].unique())} workspaces")
        print(f"üü¢ '{table_name}' table saved to the Lakehouse")
    return result_df

# Defining a function to render app by accepting the input dataframe generated by the above function.
def launch_enhanced_refresh_ui(input_df, show_author: bool = True):
    """
    Launches an interactive, enhanced UI for refreshing semantic models.
    This function creates a user interface for selecting workspaces, models, tables, and partitions from the provided DataFrame.
    It allows users to configure advanced refresh options such as refresh type, retry count, parallelism, commit mode, and policy application.
    The UI supports search and filtering for artifacts and dynamically updates available options based on user selections.
    Upon triggering the refresh, the function leverages sempy under the hood to trace the refresh activities.
    Parameters
    ----------
    input_df : pandas.DataFrame
        A DataFrame containing at least the columns: "Workspace Name", "Workspace Id", "Dataset Name", "Dataset Id", "Table Name", "Partition Name" and "Workspace Flag".
        This DataFrame is used to populate the dropdowns and selection widgets in the UI.
    Returns
    -------
    None
        Displays the interactive UI in a Notebook environment.
    """
    # Core Widgets
    workspace_search = widgets.Text(placeholder="Search workspaces...", layout=widgets.Layout(width="100%", margin='0 0 4px 0'))
    dataset_search = widgets.Text(placeholder="Search semantic models...", layout=widgets.Layout(width="100%", margin='0 0 4px 0'))
    table_search = widgets.Text(placeholder="Search tables...", layout=widgets.Layout(width="100%", margin='0 0 4px 0'))
    partition_search = widgets.Text(placeholder="Search partitions...", layout=widgets.Layout(width="100%", margin='0 0 4px 0'))

    workspace_dd = widgets.Dropdown(options=sorted(input_df["Workspace Name"].dropna().unique()), layout=widgets.Layout(width="100%"))
    dataset_dd = widgets.Dropdown(options=[], layout=widgets.Layout(width="100%"))
    tables_ms = widgets.SelectMultiple(options=[], layout=widgets.Layout(width="100%", height="120px"))
    partitions_ms = widgets.SelectMultiple(options=[], layout=widgets.Layout(width="100%", height="120px"))
    # Advanced settings widgets
    adv_style = {"description_width": "140px"}
    adv_layout = widgets.Layout(width="360px")
    refresh_type_dd = widgets.Dropdown(options=["full", "clearValues", "calculate", "dataOnly", "automatic", "defragment"], value="full", description="Refresh Type:", style=adv_style, layout=adv_layout)
    retry_count_is = widgets.IntSlider(value=0, min=0, max=10, description="Retry Count:", style=adv_style, layout=adv_layout)
    retry_count_is.style.handle_color = 'lightblue'
    apply_policy_cb = widgets.Checkbox(value=False, description="Apply Refresh Policy")
    max_parallelism_is = widgets.IntSlider(value=10, min=1, max=32, description="Max Parallelism:", style=adv_style, layout=adv_layout)
    max_parallelism_is.style.handle_color = 'lightblue'
    commit_mode_dd = widgets.Dropdown(options=["transactional", "partialBatch"], value="transactional", description="Commit Mode:", style=adv_style, layout=adv_layout)
    visualize_cb = widgets.Checkbox(value=True, description="Visualize Refresh")
    refresh_btn = widgets.Button(description="Refresh", layout=widgets.Layout(width="150px", height="40px"),style=dict(font_weight='bold',text_color='white'))
    refresh_btn.style.button_color  = '#00a69c'
    status_out = widgets.Output()
    # --- Dynamic label update logic ---
    workspace_label = widgets.HTML()
    dataset_label = widgets.HTML()
    tables_label = widgets.HTML()
    partitions_label = widgets.HTML()

    def update_labels():
        workspace_label.value = f"<b style='font-size:14px'>üóÇÔ∏è Workspaces</b> ({get_workspace_count()})"
        dataset_label.value = f"<b style='font-size:14px'>üìÖ Semantic Models</b> ({get_dataset_count()})  <span style='color:gray; font-size:12px;'>(Updates based on workspace selection)</span>"
        tables_label.value = f"<b style='font-size:14px'>ùÑú Tables</b> ({get_tables_count()}/{get_tables_total()}) <span style='color:gray; font-size:12px;'>(Hold Ctrl/Cmd to select multiple)</span>"
        partitions_label.value = f"<b style='font-size:14px'>üß© Partitions</b> ({get_partitions_count()}/{get_partitions_total()}) <span style='color:gray; font-size:12px;'>(Updates based on table selection)</span>"

    #  Helpers
    def _get_id(column, **filters):
        query = " and ".join(f"`{k}` == '{v}'" for k, v in filters.items())
        ids = input_df.query(query)[column].dropna().unique()
        return ids[0] if len(ids) > 0 else None
    def _get_partition_pairs(ws, ds, tables):
        if not tables: return []
        subset = input_df.query("`Workspace Name` == @ws and `Dataset Name` == @ds and `Table Name` in @tables")[["Table Name", "Partition Name"]].dropna().drop_duplicates()
        return sorted([(f"{tbl} ‚Äî {part}", f"'{tbl}'[{part}]") for tbl, part in subset.itertuples(index=False)])
    # Store full lists for filtering
    all_workspaces = sorted(input_df["Workspace Name"].dropna().unique())

    # --- Count update logic ---
    def get_workspace_count():
        return len(workspace_dd.options) if hasattr(workspace_dd, "options") else 0
    def get_dataset_count():
        return len(dataset_dd.options) if hasattr(dataset_dd, "options") else 0
    def get_tables_count():
        return len(tables_ms.value) if hasattr(tables_ms, "value") else 0
    def get_tables_total():
        return len(tables_ms.options) if hasattr(tables_ms, "options") else 0
    def get_partitions_count():
        return len(partitions_ms.value) if hasattr(partitions_ms, "value") else 0
    def get_partitions_total():
        return len(partitions_ms.options) if hasattr(partitions_ms, "options") else 0

    # Workspace search
    def on_workspace_search(change):
        search_term = change.new.lower()
        filtered_workspaces = [w for w in all_workspaces if search_term in w.lower()]
        current_val = workspace_dd.value
        workspace_dd.options = filtered_workspaces
        if current_val in filtered_workspaces:
            workspace_dd.value = current_val
        update_labels()

    # Dataset search
    def on_dataset_search(change):
        search_term = change.new.lower()
        ws = workspace_dd.value
        if not ws: return
        datasets = sorted(input_df.loc[input_df["Workspace Name"] == ws, "Dataset Name"].dropna().unique())
        global all_datasets
        all_datasets = datasets
        filtered_datasets = [d for d in datasets if search_term in d.lower()]
        current_val = dataset_dd.value
        dataset_dd.options = filtered_datasets
        if current_val in filtered_datasets:
            dataset_dd.value = current_val
        update_labels()

    # Table search
    def on_table_search(change):
        search_term = change.new.lower()
        ws, ds = workspace_dd.value, dataset_dd.value
        if not ws or not ds: return
        tables = sorted(input_df.loc[(input_df["Workspace Name"] == ws) & (input_df["Dataset Name"] == ds), "Table Name"].dropna().unique())
        global all_tables
        all_tables = tables
        filtered_tables = [t for t in tables if search_term in t.lower()]
        current_val = tables_ms.value
        tables_ms.options = filtered_tables
        # Only keep selected values that are still in filtered_tables
        tables_ms.value = tuple([v for v in current_val if v in filtered_tables])
        update_labels()

    # Partition search
    def on_partition_search(change):
        search_term = change.new.lower()
        ws, ds = workspace_dd.value, dataset_dd.value
        selected_tables = list(tables_ms.value)
        if not ws or not ds or not selected_tables: 
            partitions_ms.options = []
            update_labels()
            return
        pairs = _get_partition_pairs(ws, ds, selected_tables)
        global all_partitions
        all_partitions = pairs
        filtered_pairs = [p for p in pairs if search_term in p[0].lower()]
        current_val = partitions_ms.value
        partitions_ms.options = filtered_pairs
        # Only keep selected values that are still in filtered_pairs
        partitions_ms.value = tuple([v for v in current_val if v in [fp[1] for fp in filtered_pairs]])
        update_labels()

    # Workspace change
    def on_workspace_change(*_):
        ws = workspace_dd.value
        dataset_search.value = ''
        datasets = sorted(input_df.loc[input_df["Workspace Name"] == ws, "Dataset Name"].dropna().unique()) if ws else []
        global all_datasets
        all_datasets = datasets
        dataset_dd.options = datasets
        dataset_dd.value = datasets[0] if datasets else None
        update_labels()

    # Dataset change
    def on_dataset_change(*_):
        ws, ds = workspace_dd.value, dataset_dd.value
        table_search.value = ''
        tables = sorted(input_df.loc[(input_df["Workspace Name"] == ws) & (input_df["Dataset Name"] == ds), "Table Name"].dropna().unique()) if ws and ds else []
        global all_tables
        all_tables = tables
        tables_ms.options = tables
        tables_ms.value = ()
        partitions_ms.value = ()
        partitions_ms.options = []
        update_labels()

    # Tables change
    def on_tables_change(*_):
        ws, ds = workspace_dd.value, dataset_dd.value
        partition_search.value = ''
        selected_tables = list(tables_ms.value)
        pairs = _get_partition_pairs(ws, ds, selected_tables)
        global all_partitions
        all_partitions = pairs
        partitions_ms.options = pairs
        partitions_ms.value = ()
        update_labels()

    # Partitions change
    def on_partitions_change(*_):
        update_labels()

    # Observe changes on all interactive widgets
    workspace_search.observe(on_workspace_search, names="value")
    dataset_search.observe(on_dataset_search, names="value")
    table_search.observe(on_table_search, names="value")
    partition_search.observe(on_partition_search, names="value")
    workspace_dd.observe(on_workspace_change, names="value")
    dataset_dd.observe(on_dataset_change, names="value")
    tables_ms.observe(on_tables_change, names="value")
    partitions_ms.observe(on_partitions_change, names="value")

    #  Refresh Trigger
    def do_refresh(_):
        status_out.clear_output()
        with status_out:
            ws_name, ds_name = workspace_dd.value, dataset_dd.value
            if not ws_name or not ds_name:
                display(HTML("<div style='color:red; font-weight:bold;'>‚úñ Please select a workspace and dataset.</div>"))
                return
            if commit_mode_dd.value == "partialBatch" and apply_policy_cb.value:
                display(HTML("<div style='color:red; font-weight:bold;'>‚úñ For partialBatch commit mode, apply_refresh_policy must be False.</div>"))
                return
            ws_id = _get_id("Workspace Id", **{"Workspace Name": ws_name})
            ds_id = _get_id("Dataset Id", **{"Workspace Name": ws_name, "Dataset Name": ds_name})
            if not ws_id or not ds_id:
                display(HTML(f"<div style='color:red; font-weight:bold;'>‚úñ Could not resolve ID for <b>{ws_name}/{ds_name}</b>.</div>"))
                return
            params = { 
                "workspace": ws_id, 
                "dataset": ds_id, 
                "tables": list(tables_ms.value) or None, 
                "partitions": list(partitions_ms.value) or None,
                "refresh_type": refresh_type_dd.value,
                "retry_count": retry_count_is.value,
                "apply_refresh_policy": apply_policy_cb.value,
                "max_parallelism": max_parallelism_is.value,
                "commit_mode": commit_mode_dd.value,
                "visualize": visualize_cb.value 
            }
            try:
                # Remove tables from tables_ms if their name appears in any selected partition string
                selected_tables = list(tables_ms.value)
                selected_partitions = list(partitions_ms.value)
                # Extract table names from partition strings of the form "'TableName'[PartitionName]"
                partition_table_names = set()
                for p in selected_partitions:
                    if isinstance(p, str) and p.startswith("'"):
                        tbl = p.split("'")[1]
                        partition_table_names.add(tbl)
                # Remove tables that are present in partition_table_names
                filtered_tables = [t for t in selected_tables if t not in partition_table_names]
                params["tables"] = filtered_tables or None
                # display(params["tables"])
                # display(selected_partitions)
                _output = refresh_semantic_model(**params)
                display(_output)
            except Exception as e:
                display(HTML(f"<div style='color:red;'> {e}</div>"))

    refresh_btn.on_click(do_refresh)
    on_workspace_change() # Initialize dataset dropdown

    # --- Dynamic label update logic ---
    workspace_label = widgets.HTML()
    dataset_label = widgets.HTML()
    tables_label = widgets.HTML()
    partitions_label = widgets.HTML()

    # def update_labels():
    #     workspace_label.value = f"<b>üóÇÔ∏è Workspaces</b> ({get_workspace_count()})"
    #     dataset_label.value = f"<b>üìÖ Semantic Models</b> ({get_dataset_count()})"
    #     tables_label.value = f"<b>ùÑú Tables</b> ({get_tables_count()}/{get_tables_total()}) <span style='color:gray; font-size:12px;'>(Hold Ctrl/Cmd to select multiple)</span>"
    #     partitions_label.value = f"<b>üß© Partitions</b> ({get_partitions_count()}/{get_partitions_total()}) <span style='color:gray; font-size:12px;'>(Updates based on table selection)</span>"

    # Helper function to create a labeled section with an optional search box
    def create_section(title_widget, widget, hint=None, search_widget=None):
        items = [title_widget]
        if hint:
            items.append(widgets.HTML(f"<div style='color:#757575; font-size:12px; margin-bottom:8px;'>{hint}</div>"))
        if search_widget:
            items.append(search_widget) # Add search box before the main widget
        items.append(widget)
        return widgets.VBox(items, layout=widgets.Layout(flex='1 1 50%', margin='0 8px'))

    #  App Assembly
    html_content_author = (
    #Main Card
    '<div style="font-size:20px;font-weight:bold;padding:10px;color:white;background:linear-gradient(90deg, #00a69c, #00a67c);'
    'border-radius:12px;display:flex;justify-content:space-between;align-items:center;">'
    '<span>‚ö°Enhanced Model Refresh UI</span>'
    # Author container
    '<div style="background: rgba(255, 255, 255, 0.9); border-radius: 8px; padding: 5px 10px; display:flex; align-items:center;">'
    # GitHub
    '<a href="https://github.com/jai-rathinavel" target="_blank" style="color:black;text-decoration:none;display:flex;'
    'align-items:center;font-size:16px;font-weight:normal;">'
    '<svg xmlns="http://www.w3.org/2000/svg" height="20px" width="20px" viewBox="0 0 24 24" fill="black" style="margin-right:8px;">'
    '<path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C7.325 19.342 6.42 19 6.42 19c-1.08-.738.082-.722.082-.722 1.2.084 1.83 1.23 1.83 1.23 1.07 1.83 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/>'
    '</svg>'
    '<span>github</span></a>'
    
    # LinkedIn
    '<a href="https://www.linkedin.com/in/jai-rathinavel/" target="_blank" style="color:black;text-decoration:none;display:flex;'
    'align-items:center;font-size:16px;font-weight:normal;margin-left:15px;">'
    '<svg xmlns="http://www.w3.org/2000/svg" height="20px" width="20px" viewBox="0 0 24 24" fill="#0077B5" style="margin-right:8px;">'
    '<path d="M20.5 2h-17A1.5 1.5 0 002 3.5v17A1.5 1.5 0 003.5 22h17a1.5 1.5 0 001.5-1.5v-17A1.5 1.5 0 0020.5 2zM8 19H5v-9h3zM6.5 '
    '8.25A1.75 1.75 0 118.25 6.5 1.75 1.75 0 016.5 8.25zM19 19h-3v-4.74c0-1.42-.6-1.93-1.38-1.93-.91 0-1.38.61-1.38 1.93V19h-3v-9h2.9v1.3a3.11 '
    '3.11 0 012.7-1.4c1.55 0 3.28.93 3.28 4.39V19z"></path></svg>'
    '<span>jai-rathinavel</span></a>'
    '</div></div>'
    )
    raw_html_content = ("<div style='font-size:20px; font-weight:bold; text-align:center; padding:10px; "
        "color:white; background:linear-gradient(90deg, #e68900, #ff9800); "
        "border-radius:12px;'>Enhanced Semantic Model Refresh</div>")
    html_content = html_content_author if show_author else raw_html_content

    # Initial label update
    update_labels()

    # Define a common layout for the advanced setting widgets for consistent sizing
    item_layout = widgets.Layout(
        width='auto', 
        flex='1 1 0%', # Allow items to grow and shrink
        margin='5px'
    )

    # Apply the layout to each widget
    refresh_type_dd.layout = item_layout
    retry_count_is.layout = item_layout
    apply_policy_cb.layout = item_layout
    max_parallelism_is.layout = item_layout
    commit_mode_dd.layout = item_layout
    visualize_cb.layout = item_layout

    # Arrange advanced settings into a 2-column flexbox layout
    advanced_settings_box = widgets.VBox([
        widgets.HBox([refresh_type_dd, max_parallelism_is], layout=widgets.Layout(justify_content='space-around')),
        widgets.HBox([retry_count_is, commit_mode_dd], layout=widgets.Layout(justify_content='space-around')),
        widgets.HBox([apply_policy_cb, visualize_cb], layout=widgets.Layout(justify_content='space-around'))
    ])

    # Rebuild the main app layout with the new advanced settings box
    app = widgets.VBox([
        widgets.HTML(html_content),widgets.HTML("<div style='height:3px'></div>"),
        widgets.VBox([
            widgets.HBox([
                create_section(workspace_label, workspace_dd, search_widget=workspace_search),
                create_section(dataset_label, dataset_dd, search_widget=dataset_search)
            ]),
            widgets.HTML("<hr style='border-top: 1px solid #e0e0e0; margin: 16px 0;'>"),
            widgets.HBox([
                create_section(tables_label, tables_ms, search_widget=table_search),
                create_section(partitions_label, partitions_ms, search_widget=partition_search)
            ]),
            widgets.HTML("<hr style='border-top: 1px solid #e0e0e0; margin: 16px 0;'>"),
            
            # Use the newly created advanced_settings_box here
            widgets.Accordion(children=[advanced_settings_box], titles=("‚öôÔ∏è Advanced Settings",)),
            
            widgets.HBox([refresh_btn], layout=widgets.Layout(justify_content="center", margin="20px 0 0 0"))
        ], 
        layout=widgets.Layout(
            border='1px solid #e0e0e0', 
            border_radius='16px', 
            padding='10px', 
            background_color='#fcfcfc', 
            box_shadow='0 4px 12px rgba(0,0,0,0.05)'
        )),
        status_out
    ])
    return display(app)
